{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptrons with Tensorflow\n",
    "\n",
    "**XBUS-512: Introduction to AI and Deep Learning**\n",
    "\n",
    "In this exercise, we will build off our first lab, where use scikit-learn's familiar API to prototype a quick multilayer perceptron, to see how to build an MLP from scratch using the TensorFlow library.\n",
    "\n",
    "\n",
    "Thanks to [this team](https://github.com/Wall-eSociety/CommentVolumeML) for figuring out the labels for this dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(url, fname):\n",
    "    \"\"\"\n",
    "    Helper method to retreive the data from the UCI ML Repository.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    outpath  = os.path.abspath(fname)\n",
    "    with open(outpath, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    return outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and unzip the data\n",
    "\n",
    "URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00363/Dataset.zip\"\n",
    "ZIPPED_FILES = \"facebook_data.zip\"\n",
    "UNZIPPED_FILES = \"facebook_data\"\n",
    "\n",
    "zipped_data = fetch_data(URL, os.path.join(\"..\", \"fixtures\", ZIPPED_FILES))\n",
    "\n",
    "with zipfile.ZipFile(os.path.join(\"..\", \"fixtures\", ZIPPED_FILES), \"r\") as zfiles:\n",
    "    zfiles.extractall(os.path.join(\"..\", \"fixtures\", UNZIPPED_FILES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>views</th>\n",
       "      <th>returns</th>\n",
       "      <th>category</th>\n",
       "      <th>derived_1</th>\n",
       "      <th>derived_2</th>\n",
       "      <th>derived_3</th>\n",
       "      <th>derived_4</th>\n",
       "      <th>derived_5</th>\n",
       "      <th>derived_6</th>\n",
       "      <th>...</th>\n",
       "      <th>friday_post</th>\n",
       "      <th>saturday_post</th>\n",
       "      <th>sunday_base</th>\n",
       "      <th>monday_base</th>\n",
       "      <th>tuesday_base</th>\n",
       "      <th>wednesday_base</th>\n",
       "      <th>thursday_base</th>\n",
       "      <th>friday_base</th>\n",
       "      <th>saturday_base</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.131200e+04</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>8.131200e+04</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.313921e+06</td>\n",
       "      <td>4667.704336</td>\n",
       "      <td>4.475377e+04</td>\n",
       "      <td>24.255633</td>\n",
       "      <td>0.707190</td>\n",
       "      <td>464.665781</td>\n",
       "      <td>55.728933</td>\n",
       "      <td>35.392255</td>\n",
       "      <td>67.588653</td>\n",
       "      <td>0.143361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146153</td>\n",
       "      <td>0.136954</td>\n",
       "      <td>0.141049</td>\n",
       "      <td>0.133400</td>\n",
       "      <td>0.138417</td>\n",
       "      <td>0.145477</td>\n",
       "      <td>0.155180</td>\n",
       "      <td>0.144997</td>\n",
       "      <td>0.141480</td>\n",
       "      <td>7.190611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.804951e+06</td>\n",
       "      <td>20561.261034</td>\n",
       "      <td>1.109279e+05</td>\n",
       "      <td>19.949156</td>\n",
       "      <td>12.169748</td>\n",
       "      <td>520.925523</td>\n",
       "      <td>85.243275</td>\n",
       "      <td>67.043844</td>\n",
       "      <td>82.836764</td>\n",
       "      <td>7.819979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353262</td>\n",
       "      <td>0.343801</td>\n",
       "      <td>0.348075</td>\n",
       "      <td>0.340008</td>\n",
       "      <td>0.345340</td>\n",
       "      <td>0.352583</td>\n",
       "      <td>0.362078</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>0.348518</td>\n",
       "      <td>36.049374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.673400e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.980000e+02</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>5.190751</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.032349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.929110e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.045000e+03</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>22.794183</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>32.565168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.204214e+06</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>5.026400e+04</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>717.000000</td>\n",
       "      <td>71.791489</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>102.060861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.869723e+08</td>\n",
       "      <td>186370.000000</td>\n",
       "      <td>6.089942e+06</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>1311.000000</td>\n",
       "      <td>2438.000000</td>\n",
       "      <td>1693.500000</td>\n",
       "      <td>1693.500000</td>\n",
       "      <td>743.091650</td>\n",
       "      <td>1311.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1966.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              likes          views       returns      category     derived_1  \\\n",
       "count  8.131200e+04   81312.000000  8.131200e+04  81312.000000  81312.000000   \n",
       "mean   1.313921e+06    4667.704336  4.475377e+04     24.255633      0.707190   \n",
       "std    6.804951e+06   20561.261034  1.109279e+05     19.949156     12.169748   \n",
       "min    3.600000e+01       0.000000  0.000000e+00      1.000000      0.000000   \n",
       "25%    3.673400e+04       0.000000  6.980000e+02      9.000000      0.000000   \n",
       "50%    2.929110e+05       0.000000  7.045000e+03     18.000000      0.000000   \n",
       "75%    1.204214e+06      99.000000  5.026400e+04     32.000000      0.000000   \n",
       "max    4.869723e+08  186370.000000  6.089942e+06    106.000000   1311.000000   \n",
       "\n",
       "          derived_2     derived_3     derived_4     derived_5     derived_6  \\\n",
       "count  81312.000000  81312.000000  81312.000000  81312.000000  81312.000000   \n",
       "mean     464.665781     55.728933     35.392255     67.588653      0.143361   \n",
       "std      520.925523     85.243275     67.043844     82.836764      7.819979   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       47.000000      5.190751      2.000000      8.032349      0.000000   \n",
       "50%      251.000000     22.794183     13.000000     32.565168      0.000000   \n",
       "75%      717.000000     71.791489     42.000000    102.060861      0.000000   \n",
       "max     2438.000000   1693.500000   1693.500000    743.091650   1311.000000   \n",
       "\n",
       "       ...   friday_post  saturday_post   sunday_base   monday_base  \\\n",
       "count  ...  81312.000000   81312.000000  81312.000000  81312.000000   \n",
       "mean   ...      0.146153       0.136954      0.141049      0.133400   \n",
       "std    ...      0.353262       0.343801      0.348075      0.340008   \n",
       "min    ...      0.000000       0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000       0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000       0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000       0.000000      0.000000      0.000000   \n",
       "max    ...      1.000000       1.000000      1.000000      1.000000   \n",
       "\n",
       "       tuesday_base  wednesday_base  thursday_base   friday_base  \\\n",
       "count  81312.000000    81312.000000   81312.000000  81312.000000   \n",
       "mean       0.138417        0.145477       0.155180      0.144997   \n",
       "std        0.345340        0.352583       0.362078      0.352100   \n",
       "min        0.000000        0.000000       0.000000      0.000000   \n",
       "25%        0.000000        0.000000       0.000000      0.000000   \n",
       "50%        0.000000        0.000000       0.000000      0.000000   \n",
       "75%        0.000000        0.000000       0.000000      0.000000   \n",
       "max        1.000000        1.000000       1.000000      1.000000   \n",
       "\n",
       "       saturday_base        target  \n",
       "count   81312.000000  81312.000000  \n",
       "mean        0.141480      7.190611  \n",
       "std         0.348518     36.049374  \n",
       "min         0.000000      0.000000  \n",
       "25%         0.000000      0.000000  \n",
       "50%         0.000000      0.000000  \n",
       "75%         0.000000      3.000000  \n",
       "max         1.000000   1966.000000  \n",
       "\n",
       "[8 rows x 54 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    os.path.join(\n",
    "        \"..\", \n",
    "        \"fixtures\", \n",
    "        UNZIPPED_FILES, \n",
    "        \"Dataset\", \n",
    "        \"Training\", \n",
    "        \"Features_Variant_2.csv\"\n",
    "    ),\n",
    "    header=None\n",
    ")\n",
    "data.columns = [\n",
    "    \"likes\", \"views\", \"returns\", \"category\", \"derived_1\", \"derived_2\", \"derived_3\",\n",
    "    \"derived_4\", \"derived_5\", \"derived_6\", \"derived_7\", \"derived_8\", \"derived_9\",\n",
    "    \"derived_10\", \"derived_11\", \"derived_12\", \"derived_13\", \"derived_14\", \"derived_15\", \n",
    "    \"derived_16\", \"derived_17\", \"derived_18\", \"derived_19\", \"derived_20\", \"derived_21\",\n",
    "    \"derived_22\", \"derived_23\", \"derived_24\", \"derived_25\", \"cc_1\", \"cc_2\", \"cc_3\",\n",
    "    \"cc_4\", \"cc_5\", \"base_time\", \"length\", \"shares\", \"status\", \"h_local\", \"sunday_post\",\n",
    "    \"monday_post\", \"tuesday_post\", \"wednesday_post\", \"thursday_post\", \"friday_post\",\n",
    "    \"saturday_post\", \"sunday_base\", \"monday_base\", \"tuesday_base\", \"wednesday_base\",\n",
    "    \"thursday_base\", \"friday_base\", \"saturday_base\", \"target\"\n",
    "]\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_regression(dataframe):\n",
    "    \"\"\"\n",
    "    Prepare the data for a regression problem where we will attempt\n",
    "    to regress the number of comments that a Facebook post will get\n",
    "    given other features of the data.\n",
    "    \n",
    "    Returns a tuple containing an nd array of features (X)\n",
    "    and a 1d array for the target (y)\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        \"likes\", \"views\", \"returns\", \"category\", \"derived_1\", \"derived_2\", \"derived_3\",\n",
    "        \"derived_4\", \"derived_5\", \"derived_6\", \"derived_7\", \"derived_8\", \"derived_9\",\n",
    "        \"derived_10\", \"derived_11\", \"derived_12\", \"derived_13\", \"derived_14\", \"derived_15\", \n",
    "        \"derived_16\", \"derived_17\", \"derived_18\", \"derived_19\", \"derived_20\", \"derived_21\",\n",
    "        \"derived_22\", \"derived_23\", \"derived_24\", \"derived_25\", \"cc_1\", \"cc_2\", \"cc_3\",\n",
    "        \"cc_4\", \"cc_5\", \"base_time\", \"length\", \"shares\", \"status\", \"h_local\", \"sunday_post\",\n",
    "        \"monday_post\", \"tuesday_post\", \"wednesday_post\", \"thursday_post\", \"friday_post\",\n",
    "        \"saturday_post\", \"sunday_base\", \"monday_base\", \"tuesday_base\", \"wednesday_base\",\n",
    "        \"thursday_base\", \"friday_base\", \"saturday_base\"     \n",
    "    ]\n",
    "    target = \"target\"\n",
    "    \n",
    "    # MLP is sensitive to feature scaling!\n",
    "    X = MinMaxScaler().fit_transform(dataframe[features].values)\n",
    "    y = dataframe[target].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def prepare_for_classification(dataframe):\n",
    "    \"\"\"\n",
    "    Prepare the data for a classification problem where we will attempt\n",
    "    to predict the category of a Facebook post given features of the data.\n",
    "    \n",
    "    Returns a tuple containing an nd array of features (X)\n",
    "    and a 1d array for the target (y)\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        \"likes\", \"views\", \"returns\", \"derived_1\", \"derived_2\", \"derived_3\",\n",
    "        \"derived_4\", \"derived_5\", \"derived_6\", \"derived_7\", \"derived_8\", \"derived_9\",\n",
    "        \"derived_10\", \"derived_11\", \"derived_12\", \"derived_13\", \"derived_14\", \"derived_15\", \n",
    "        \"derived_16\", \"derived_17\", \"derived_18\", \"derived_19\", \"derived_20\", \"derived_21\",\n",
    "        \"derived_22\", \"derived_23\", \"derived_24\", \"derived_25\", \"cc_1\", \"cc_2\", \"cc_3\",\n",
    "        \"cc_4\", \"cc_5\", \"base_time\", \"length\", \"shares\", \"status\", \"h_local\", \"sunday_post\",\n",
    "        \"monday_post\", \"tuesday_post\", \"wednesday_post\", \"thursday_post\", \"friday_post\",\n",
    "        \"saturday_post\", \"sunday_base\", \"monday_base\", \"tuesday_base\", \"wednesday_base\",\n",
    "        \"thursday_base\", \"friday_base\", \"saturday_base\", \"target\"     \n",
    "    ]\n",
    "    target = \"category\"\n",
    "    \n",
    "    # MLP is sensitive to feature scaling!\n",
    "    X = MinMaxScaler().fit_transform(dataframe[features].values)\n",
    "    y = dataframe[target].values\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data and break in to training and test splits\n",
    "X, y = prepare_for_regression(data)\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(X.shape[1],))\n",
    "dense_layer_1 = Dense(100, activation=\"relu\")(input_layer)\n",
    "dense_layer_2 = Dense(50, activation=\"relu\")(dense_layer_1)\n",
    "dense_layer_3 = Dense(25, activation=\"relu\")(dense_layer_2)\n",
    "output = Dense(1)(dense_layer_3)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\", \n",
    "    optimizer=\"adam\", \n",
    "    metrics=[\"mean_squared_error\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & evaluate the model\n",
    "\n",
    "Examine the differences in F1/R2 score and training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32525/32525 [==============================] - 61s 2ms/step - loss: 793.5829 - mean_squared_error: 793.5829\n",
      "Epoch 2/100\n",
      "32525/32525 [==============================] - 60s 2ms/step - loss: 683.2601 - mean_squared_error: 683.2601\n",
      "Epoch 3/100\n",
      "32525/32525 [==============================] - 57s 2ms/step - loss: 641.2027 - mean_squared_error: 641.2027 0s - loss: 648.6770 - mean_squared_error: 64 - ETA: 0s - loss:\n",
      "Epoch 4/100\n",
      "32525/32525 [==============================] - 59s 2ms/step - loss: 599.8335 - mean_squared_error: 599.8335\n",
      "Epoch 5/100\n",
      "32525/32525 [==============================] - 56s 2ms/step - loss: 595.2052 - mean_squared_error: 595.2052\n",
      "Epoch 6/100\n",
      "32525/32525 [==============================] - 58s 2ms/step - loss: 566.7728 - mean_squared_error: 566.7728\n",
      "Epoch 7/100\n",
      "32525/32525 [==============================] - 60s 2ms/step - loss: 575.5735 - mean_squared_error: 575.5735 3s - loss: 549.0684 -  - ETA: 3s - loss: 546.2039 - mean_squared_err - ETA: 1s - loss: 564.8655 - me - ETA: 1s -\n",
      "Epoch 8/100\n",
      "32525/32525 [==============================] - 56s 2ms/step - loss: 546.6882 - mean_squared_error: 546.6882\n",
      "Epoch 9/100\n",
      "32525/32525 [==============================] - 58s 2ms/step - loss: 530.3927 - mean_squared_error: 530.3927\n",
      "Epoch 10/100\n",
      "32525/32525 [==============================] - 55s 2ms/step - loss: 527.2162 - mean_squared_error: 527.2162\n",
      "Epoch 11/100\n",
      "32525/32525 [==============================] - 54s 2ms/step - loss: 531.1550 - mean_squared_error: 531.1550\n",
      "Epoch 12/100\n",
      "32525/32525 [==============================] - 55s 2ms/step - loss: 489.3247 - mean_squared_error: 489.3247\n",
      "Epoch 13/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 513.7392 - mean_squared_error: 513.7392 0s - loss: 516.4713 - mean_squar\n",
      "Epoch 14/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 501.1223 - mean_squared_error: 501.1223\n",
      "Epoch 15/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 502.7988 - mean_squared_error: 502.7988\n",
      "Epoch 16/100\n",
      "32525/32525 [==============================] - 45s 1ms/step - loss: 487.2518 - mean_squared_error: 487.2518\n",
      "Epoch 17/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 485.6438 - mean_squared_error: 485.6438\n",
      "Epoch 18/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 477.3074 - mean_squared_error: 477.3074\n",
      "Epoch 19/100\n",
      "32525/32525 [==============================] - 45s 1ms/step - loss: 465.9463 - mean_squared_error: 465.9463\n",
      "Epoch 20/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 446.3633 - mean_squared_error: 446.3633\n",
      "Epoch 21/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 451.8050 - mean_squared_error: 451.8050\n",
      "Epoch 22/100\n",
      "32525/32525 [==============================] - 45s 1ms/step - loss: 453.8707 - mean_squared_error: 453.8707\n",
      "Epoch 23/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 445.2968 - mean_squared_error: 445.2968\n",
      "Epoch 24/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 434.3741 - mean_squared_error: 434.3741\n",
      "Epoch 25/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 426.3004 - mean_squared_error: 426.3004\n",
      "Epoch 26/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 442.5839 - mean_squared_error: 442.5839\n",
      "Epoch 27/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 434.0300 - mean_squared_error: 434.0300\n",
      "Epoch 28/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 424.8824 - mean_squared_error: 424.8824\n",
      "Epoch 29/100\n",
      "32525/32525 [==============================] - 47s 1ms/step - loss: 406.6576 - mean_squared_error: 406.6576\n",
      "Epoch 30/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 412.3099 - mean_squared_error: 412.3099\n",
      "Epoch 31/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 401.8719 - mean_squared_error: 401.8719\n",
      "Epoch 32/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 406.9484 - mean_squared_error: 406.9484\n",
      "Epoch 33/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 399.7213 - mean_squared_error: 399.7213\n",
      "Epoch 34/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 395.7118 - mean_squared_error: 395.7118 1s - los\n",
      "Epoch 35/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 395.9171 - mean_squared_error: 395.9171\n",
      "Epoch 36/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 414.6106 - mean_squared_error: 414.6106\n",
      "Epoch 37/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 392.7135 - mean_squared_error: 392.7135\n",
      "Epoch 38/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 406.4115 - mean_squared_error: 406.4115 0s - loss: 407.5857 - mean_squared_e\n",
      "Epoch 39/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 391.6429 - mean_squared_error: 391.6429\n",
      "Epoch 40/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 400.7163 - mean_squared_error: 400.7163\n",
      "Epoch 41/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 391.4328 - mean_squared_error: 391.4328\n",
      "Epoch 42/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 379.3967 - mean_squared_error: 379.3967\n",
      "Epoch 43/100\n",
      "32525/32525 [==============================] - 46s 1ms/step - loss: 390.8768 - mean_squared_error: 390.8768\n",
      "Epoch 44/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 382.2490 - mean_squared_error: 382.2490\n",
      "Epoch 45/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 382.1264 - mean_squared_error: 382.1264\n",
      "Epoch 46/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 376.6018 - mean_squared_error: 376.6018\n",
      "Epoch 47/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 377.7976 - mean_squared_error: 377.7976\n",
      "Epoch 48/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 367.7476 - mean_squared_error: 367.7476\n",
      "Epoch 49/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 384.2993 - mean_squared_error: 384.2993\n",
      "Epoch 50/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 373.2966 - mean_squared_error: 373.2966\n",
      "Epoch 51/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 369.8782 - mean_squared_error: 369.8782\n",
      "Epoch 52/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 374.1392 - mean_squared_error: 374.1392\n",
      "Epoch 53/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 374.0688 - mean_squared_error: 374.0688\n",
      "Epoch 54/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 350.3432 - mean_squared_error: 350.3432\n",
      "Epoch 55/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 365.5324 - mean_squared_error: 365.5324\n",
      "Epoch 56/100\n",
      "32525/32525 [==============================] - 47s 1ms/step - loss: 366.1657 - mean_squared_error: 366.1657\n",
      "Epoch 57/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 358.0407 - mean_squared_error: 358.0407\n",
      "Epoch 58/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 347.2530 - mean_squared_error: 347.2530\n",
      "Epoch 59/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 359.3112 - mean_squared_error: 359.3112\n",
      "Epoch 60/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 362.9857 - mean_squared_error: 362.9857 3s - loss: 369.7227 - me\n",
      "Epoch 61/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 352.2827 - mean_squared_error: 352.2827\n",
      "Epoch 62/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 355.4700 - mean_squared_error: 355.4700\n",
      "Epoch 63/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 342.8696 - mean_squared_error: 342.8696\n",
      "Epoch 64/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 351.4215 - mean_squared_error: 351.4215\n",
      "Epoch 65/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 354.6934 - mean_squared_error: 354.6934\n",
      "Epoch 66/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 341.4267 - mean_squared_error: 341.4267\n",
      "Epoch 67/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 341.4853 - mean_squared_error: 341.4853\n",
      "Epoch 68/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 346.5776 - mean_squared_error: 346.5776\n",
      "Epoch 69/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 350.8121 - mean_squared_error: 350.8121\n",
      "Epoch 70/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 346.7150 - mean_squared_error: 346.7150\n",
      "Epoch 71/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 343.0478 - mean_squared_error: 343.0478 0s - loss: 340.0822 - mean_squared_error: \n",
      "Epoch 72/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 335.1148 - mean_squared_error: 335.1148\n",
      "Epoch 73/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 342.8267 - mean_squared_error: 342.8267\n",
      "Epoch 74/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 333.3496 - mean_squared_error: 333.3496\n",
      "Epoch 75/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 329.7623 - mean_squared_error: 329.7623\n",
      "Epoch 76/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 331.4825 - mean_squared_error: 331.4825\n",
      "Epoch 77/100\n",
      "32525/32525 [==============================] - 45s 1ms/step - loss: 332.8656 - mean_squared_error: 332.8656\n",
      "Epoch 78/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 338.4808 - mean_squared_error: 338.4808\n",
      "Epoch 79/100\n",
      "32525/32525 [==============================] - 45s 1ms/step - loss: 343.1974 - mean_squared_error: 343.1974\n",
      "Epoch 80/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 325.4958 - mean_squared_error: 325.4958\n",
      "Epoch 81/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 344.2996 - mean_squared_error: 344.2996\n",
      "Epoch 82/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 328.0402 - mean_squared_error: 328.0402\n",
      "Epoch 83/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 324.8031 - mean_squared_error: 324.8031\n",
      "Epoch 84/100\n",
      "32525/32525 [==============================] - 49s 1ms/step - loss: 334.3386 - mean_squared_error: 334.3386 1s -\n",
      "Epoch 85/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 328.1747 - mean_squared_error: 328.1747\n",
      "Epoch 86/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 318.2264 - mean_squared_error: 318.2264\n",
      "Epoch 87/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 317.0926 - mean_squared_error: 317.0926\n",
      "Epoch 88/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 313.4180 - mean_squared_error: 313.4180\n",
      "Epoch 89/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 313.6999 - mean_squared_error: 313.6999\n",
      "Epoch 90/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 330.6243 - mean_squared_error: 330.6243\n",
      "Epoch 91/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 322.8159 - mean_squared_error: 322.8159\n",
      "Epoch 92/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 317.1593 - mean_squared_error: 317.1593\n",
      "Epoch 93/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 325.4369 - mean_squared_error: 325.4369\n",
      "Epoch 94/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 313.4199 - mean_squared_error: 313.4199\n",
      "Epoch 95/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 319.0644 - mean_squared_error: 319.0644\n",
      "Epoch 96/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 304.2752 - mean_squared_error: 304.2752\n",
      "Epoch 97/100\n",
      "32525/32525 [==============================] - 45s 1ms/step - loss: 327.4688 - mean_squared_error: 327.4688\n",
      "Epoch 98/100\n",
      "32525/32525 [==============================] - 44s 1ms/step - loss: 303.5453 - mean_squared_error: 303.5453\n",
      "Epoch 99/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 308.5285 - mean_squared_error: 308.5285\n",
      "Epoch 100/100\n",
      "32525/32525 [==============================] - 43s 1ms/step - loss: 316.8783 - mean_squared_error: 316.8783\n",
      "Training took 4560.346438884735 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    batch_size=2, \n",
    "    epochs=100, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training took {} seconds\".format(\n",
    "    time.time() - start\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 17.02623300964482\n",
      "Test error: 21.89543327062504\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(X_train)\n",
    "print(\"Training error: {}\".format(\n",
    "    np.sqrt(mean_squared_error(y_train, pred_train))\n",
    "))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(\"Test error: {}\".format(\n",
    "    np.sqrt(mean_squared_error(y_test, pred))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = os.path.join(\"..\", \"results\")\n",
    "\n",
    "if not os.path.exists(RESULTS):\n",
    "    os.makedirs(RESULTS)\n",
    "    \n",
    "filename = os.path.join(RESULTS, \"tensorflow_model.h5\")\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the model and run live predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
