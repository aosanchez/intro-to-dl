{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptrons with Tensorflow\n",
    "\n",
    "**XBUS-512: Introduction to AI and Deep Learning**\n",
    "\n",
    "In this exercise, we will build off our first lab, where use scikit-learn's familiar API to prototype a quick multilayer perceptron, to see how to build an MLP from scratch using the TensorFlow library.\n",
    "\n",
    "\n",
    "Thanks to [this team](https://github.com/Wall-eSociety/CommentVolumeML) for figuring out the labels for this dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(url, fname):\n",
    "    \"\"\"\n",
    "    Helper method to retreive the data from the UCI ML Repository.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    outpath  = os.path.abspath(fname)\n",
    "    with open(outpath, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    return outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and unzip the data\n",
    "\n",
    "URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00363/Dataset.zip\"\n",
    "ZIPPED_FILES = \"facebook_data.zip\"\n",
    "UNZIPPED_FILES = \"facebook_data\"\n",
    "\n",
    "zipped_data = fetch_data(URL, os.path.join(\"..\", \"fixtures\", ZIPPED_FILES))\n",
    "\n",
    "with zipfile.ZipFile(os.path.join(\"..\", \"fixtures\", ZIPPED_FILES), \"r\") as zfiles:\n",
    "    zfiles.extractall(os.path.join(\"..\", \"fixtures\", UNZIPPED_FILES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>views</th>\n",
       "      <th>returns</th>\n",
       "      <th>category</th>\n",
       "      <th>derived_1</th>\n",
       "      <th>derived_2</th>\n",
       "      <th>derived_3</th>\n",
       "      <th>derived_4</th>\n",
       "      <th>derived_5</th>\n",
       "      <th>derived_6</th>\n",
       "      <th>...</th>\n",
       "      <th>friday_post</th>\n",
       "      <th>saturday_post</th>\n",
       "      <th>sunday_base</th>\n",
       "      <th>monday_base</th>\n",
       "      <th>tuesday_base</th>\n",
       "      <th>wednesday_base</th>\n",
       "      <th>thursday_base</th>\n",
       "      <th>friday_base</th>\n",
       "      <th>saturday_base</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.131200e+04</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>8.131200e+04</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.313921e+06</td>\n",
       "      <td>4667.704336</td>\n",
       "      <td>4.475377e+04</td>\n",
       "      <td>24.255633</td>\n",
       "      <td>0.707190</td>\n",
       "      <td>464.665781</td>\n",
       "      <td>55.728933</td>\n",
       "      <td>35.392255</td>\n",
       "      <td>67.588653</td>\n",
       "      <td>0.143361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146153</td>\n",
       "      <td>0.136954</td>\n",
       "      <td>0.141049</td>\n",
       "      <td>0.133400</td>\n",
       "      <td>0.138417</td>\n",
       "      <td>0.145477</td>\n",
       "      <td>0.155180</td>\n",
       "      <td>0.144997</td>\n",
       "      <td>0.141480</td>\n",
       "      <td>7.190611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.804951e+06</td>\n",
       "      <td>20561.261034</td>\n",
       "      <td>1.109279e+05</td>\n",
       "      <td>19.949156</td>\n",
       "      <td>12.169748</td>\n",
       "      <td>520.925523</td>\n",
       "      <td>85.243275</td>\n",
       "      <td>67.043844</td>\n",
       "      <td>82.836764</td>\n",
       "      <td>7.819979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353262</td>\n",
       "      <td>0.343801</td>\n",
       "      <td>0.348075</td>\n",
       "      <td>0.340008</td>\n",
       "      <td>0.345340</td>\n",
       "      <td>0.352583</td>\n",
       "      <td>0.362078</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>0.348518</td>\n",
       "      <td>36.049374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.673400e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.980000e+02</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>5.190751</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.032349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.929110e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.045000e+03</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>22.794183</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>32.565168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.204214e+06</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>5.026400e+04</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>717.000000</td>\n",
       "      <td>71.791489</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>102.060861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.869723e+08</td>\n",
       "      <td>186370.000000</td>\n",
       "      <td>6.089942e+06</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>1311.000000</td>\n",
       "      <td>2438.000000</td>\n",
       "      <td>1693.500000</td>\n",
       "      <td>1693.500000</td>\n",
       "      <td>743.091650</td>\n",
       "      <td>1311.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1966.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              likes          views       returns      category     derived_1  \\\n",
       "count  8.131200e+04   81312.000000  8.131200e+04  81312.000000  81312.000000   \n",
       "mean   1.313921e+06    4667.704336  4.475377e+04     24.255633      0.707190   \n",
       "std    6.804951e+06   20561.261034  1.109279e+05     19.949156     12.169748   \n",
       "min    3.600000e+01       0.000000  0.000000e+00      1.000000      0.000000   \n",
       "25%    3.673400e+04       0.000000  6.980000e+02      9.000000      0.000000   \n",
       "50%    2.929110e+05       0.000000  7.045000e+03     18.000000      0.000000   \n",
       "75%    1.204214e+06      99.000000  5.026400e+04     32.000000      0.000000   \n",
       "max    4.869723e+08  186370.000000  6.089942e+06    106.000000   1311.000000   \n",
       "\n",
       "          derived_2     derived_3     derived_4     derived_5     derived_6  \\\n",
       "count  81312.000000  81312.000000  81312.000000  81312.000000  81312.000000   \n",
       "mean     464.665781     55.728933     35.392255     67.588653      0.143361   \n",
       "std      520.925523     85.243275     67.043844     82.836764      7.819979   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       47.000000      5.190751      2.000000      8.032349      0.000000   \n",
       "50%      251.000000     22.794183     13.000000     32.565168      0.000000   \n",
       "75%      717.000000     71.791489     42.000000    102.060861      0.000000   \n",
       "max     2438.000000   1693.500000   1693.500000    743.091650   1311.000000   \n",
       "\n",
       "       ...   friday_post  saturday_post   sunday_base   monday_base  \\\n",
       "count  ...  81312.000000   81312.000000  81312.000000  81312.000000   \n",
       "mean   ...      0.146153       0.136954      0.141049      0.133400   \n",
       "std    ...      0.353262       0.343801      0.348075      0.340008   \n",
       "min    ...      0.000000       0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000       0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000       0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000       0.000000      0.000000      0.000000   \n",
       "max    ...      1.000000       1.000000      1.000000      1.000000   \n",
       "\n",
       "       tuesday_base  wednesday_base  thursday_base   friday_base  \\\n",
       "count  81312.000000    81312.000000   81312.000000  81312.000000   \n",
       "mean       0.138417        0.145477       0.155180      0.144997   \n",
       "std        0.345340        0.352583       0.362078      0.352100   \n",
       "min        0.000000        0.000000       0.000000      0.000000   \n",
       "25%        0.000000        0.000000       0.000000      0.000000   \n",
       "50%        0.000000        0.000000       0.000000      0.000000   \n",
       "75%        0.000000        0.000000       0.000000      0.000000   \n",
       "max        1.000000        1.000000       1.000000      1.000000   \n",
       "\n",
       "       saturday_base        target  \n",
       "count   81312.000000  81312.000000  \n",
       "mean        0.141480      7.190611  \n",
       "std         0.348518     36.049374  \n",
       "min         0.000000      0.000000  \n",
       "25%         0.000000      0.000000  \n",
       "50%         0.000000      0.000000  \n",
       "75%         0.000000      3.000000  \n",
       "max         1.000000   1966.000000  \n",
       "\n",
       "[8 rows x 54 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    os.path.join(\n",
    "        \"..\", \n",
    "        \"fixtures\", \n",
    "        UNZIPPED_FILES, \n",
    "        \"Dataset\", \n",
    "        \"Training\", \n",
    "        \"Features_Variant_2.csv\"\n",
    "    ),\n",
    "    header=None\n",
    ")\n",
    "data.columns = [\n",
    "    \"likes\", \"views\", \"returns\", \"category\", \"derived_1\", \"derived_2\", \"derived_3\",\n",
    "    \"derived_4\", \"derived_5\", \"derived_6\", \"derived_7\", \"derived_8\", \"derived_9\",\n",
    "    \"derived_10\", \"derived_11\", \"derived_12\", \"derived_13\", \"derived_14\", \"derived_15\", \n",
    "    \"derived_16\", \"derived_17\", \"derived_18\", \"derived_19\", \"derived_20\", \"derived_21\",\n",
    "    \"derived_22\", \"derived_23\", \"derived_24\", \"derived_25\", \"cc_1\", \"cc_2\", \"cc_3\",\n",
    "    \"cc_4\", \"cc_5\", \"base_time\", \"length\", \"shares\", \"status\", \"h_local\", \"sunday_post\",\n",
    "    \"monday_post\", \"tuesday_post\", \"wednesday_post\", \"thursday_post\", \"friday_post\",\n",
    "    \"saturday_post\", \"sunday_base\", \"monday_base\", \"tuesday_base\", \"wednesday_base\",\n",
    "    \"thursday_base\", \"friday_base\", \"saturday_base\", \"target\"\n",
    "]\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_regression(dataframe):\n",
    "    \"\"\"\n",
    "    Prepare the data for a regression problem where we will attempt\n",
    "    to regress the number of comments that a Facebook post will get\n",
    "    given other features of the data.\n",
    "    \n",
    "    Returns a tuple containing an nd array of features (X)\n",
    "    and a 1d array for the target (y)\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        \"likes\", \"views\", \"returns\", \"category\", \"derived_1\", \"derived_2\", \"derived_3\",\n",
    "        \"derived_4\", \"derived_5\", \"derived_6\", \"derived_7\", \"derived_8\", \"derived_9\",\n",
    "        \"derived_10\", \"derived_11\", \"derived_12\", \"derived_13\", \"derived_14\", \"derived_15\", \n",
    "        \"derived_16\", \"derived_17\", \"derived_18\", \"derived_19\", \"derived_20\", \"derived_21\",\n",
    "        \"derived_22\", \"derived_23\", \"derived_24\", \"derived_25\", \"cc_1\", \"cc_2\", \"cc_3\",\n",
    "        \"cc_4\", \"cc_5\", \"base_time\", \"length\", \"shares\", \"status\", \"h_local\", \"sunday_post\",\n",
    "        \"monday_post\", \"tuesday_post\", \"wednesday_post\", \"thursday_post\", \"friday_post\",\n",
    "        \"saturday_post\", \"sunday_base\", \"monday_base\", \"tuesday_base\", \"wednesday_base\",\n",
    "        \"thursday_base\", \"friday_base\", \"saturday_base\"     \n",
    "    ]\n",
    "    target = \"target\"\n",
    "    \n",
    "    # MLP is sensitive to feature scaling!\n",
    "    X = MinMaxScaler().fit_transform(dataframe[features].values)\n",
    "    y = dataframe[target].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def prepare_for_classification(dataframe):\n",
    "    \"\"\"\n",
    "    Prepare the data for a classification problem where we will attempt\n",
    "    to predict the category of a Facebook post given features of the data.\n",
    "    \n",
    "    Returns a tuple containing an nd array of features (X)\n",
    "    and a 1d array for the target (y)\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        \"likes\", \"views\", \"returns\", \"derived_1\", \"derived_2\", \"derived_3\",\n",
    "        \"derived_4\", \"derived_5\", \"derived_6\", \"derived_7\", \"derived_8\", \"derived_9\",\n",
    "        \"derived_10\", \"derived_11\", \"derived_12\", \"derived_13\", \"derived_14\", \"derived_15\", \n",
    "        \"derived_16\", \"derived_17\", \"derived_18\", \"derived_19\", \"derived_20\", \"derived_21\",\n",
    "        \"derived_22\", \"derived_23\", \"derived_24\", \"derived_25\", \"cc_1\", \"cc_2\", \"cc_3\",\n",
    "        \"cc_4\", \"cc_5\", \"base_time\", \"length\", \"shares\", \"status\", \"h_local\", \"sunday_post\",\n",
    "        \"monday_post\", \"tuesday_post\", \"wednesday_post\", \"thursday_post\", \"friday_post\",\n",
    "        \"saturday_post\", \"sunday_base\", \"monday_base\", \"tuesday_base\", \"wednesday_base\",\n",
    "        \"thursday_base\", \"friday_base\", \"saturday_base\", \"target\"     \n",
    "    ]\n",
    "    target = \"category\"\n",
    "    \n",
    "    # MLP is sensitive to feature scaling!\n",
    "    X = MinMaxScaler().fit_transform(dataframe[features].values)\n",
    "    y = dataframe[target].values\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data and break in to training and test splits\n",
    "X, y = prepare_for_regression(data)\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(X.shape[1],))\n",
    "dense_layer_1 = Dense(100, activation=\"relu\")(input_layer)\n",
    "dense_layer_2 = Dense(50, activation=\"relu\")(dense_layer_1)\n",
    "dense_layer_3 = Dense(25, activation=\"relu\")(dense_layer_2)\n",
    "output = Dense(1)(dense_layer_3)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\", \n",
    "    optimizer=\"adam\", \n",
    "    metrics=[\"mean_squared_error\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & evaluate the model\n",
    "\n",
    "Examine the differences in F1/R2 score and training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32525/32525 [==============================] - 99s 3ms/step - loss: 797.0344 - mean_squared_error: 797.0344\n",
      "Epoch 2/100\n",
      "32525/32525 [==============================] - 93s 3ms/step - loss: 700.1571 - mean_squared_error: 700.1571\n",
      "Epoch 3/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 629.4226 - mean_squared_error: 629.4226\n",
      "Epoch 4/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 596.6333 - mean_squared_error: 596.6333\n",
      "Epoch 5/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 586.5175 - mean_squared_error: 586.5175\n",
      "Epoch 6/100\n",
      "32525/32525 [==============================] - 105s 3ms/step - loss: 570.5201 - mean_squared_error: 570.5201\n",
      "Epoch 7/100\n",
      "32525/32525 [==============================] - 105s 3ms/step - loss: 562.3015 - mean_squared_error: 562.3015\n",
      "Epoch 8/100\n",
      "32525/32525 [==============================] - 104s 3ms/step - loss: 542.6069 - mean_squared_error: 542.6069\n",
      "Epoch 9/100\n",
      "32525/32525 [==============================] - 108s 3ms/step - loss: 536.5471 - mean_squared_error: 536.5471\n",
      "Epoch 10/100\n",
      "32525/32525 [==============================] - 93s 3ms/step - loss: 514.5941 - mean_squared_error: 514.5941\n",
      "Epoch 11/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 493.7256 - mean_squared_error: 493.7256\n",
      "Epoch 12/100\n",
      "32525/32525 [==============================] - 96s 3ms/step - loss: 512.0914 - mean_squared_error: 512.0914\n",
      "Epoch 13/100\n",
      "32525/32525 [==============================] - 93s 3ms/step - loss: 497.7566 - mean_squared_error: 497.7566\n",
      "Epoch 14/100\n",
      "32525/32525 [==============================] - 93s 3ms/step - loss: 523.2928 - mean_squared_error: 523.2928\n",
      "Epoch 15/100\n",
      "32525/32525 [==============================] - 108s 3ms/step - loss: 494.2488 - mean_squared_error: 494.2488\n",
      "Epoch 16/100\n",
      "32525/32525 [==============================] - 111s 3ms/step - loss: 491.0506 - mean_squared_error: 491.0506\n",
      "Epoch 17/100\n",
      "32525/32525 [==============================] - 115s 4ms/step - loss: 481.2964 - mean_squared_error: 481.2964\n",
      "Epoch 18/100\n",
      "32525/32525 [==============================] - 120s 4ms/step - loss: 458.4458 - mean_squared_error: 458.4458\n",
      "Epoch 19/100\n",
      "32525/32525 [==============================] - 120s 4ms/step - loss: 480.9330 - mean_squared_error: 480.9330\n",
      "Epoch 20/100\n",
      "32525/32525 [==============================] - 103s 3ms/step - loss: 459.2217 - mean_squared_error: 459.2217\n",
      "Epoch 21/100\n",
      "32525/32525 [==============================] - 106s 3ms/step - loss: 443.9004 - mean_squared_error: 443.9004\n",
      "Epoch 22/100\n",
      "32525/32525 [==============================] - 102s 3ms/step - loss: 439.5807 - mean_squared_error: 439.5807\n",
      "Epoch 23/100\n",
      "32525/32525 [==============================] - 101s 3ms/step - loss: 464.5048 - mean_squared_error: 464.5048\n",
      "Epoch 24/100\n",
      "32525/32525 [==============================] - 97s 3ms/step - loss: 447.8557 - mean_squared_error: 447.8557\n",
      "Epoch 25/100\n",
      "32525/32525 [==============================] - 93s 3ms/step - loss: 453.0331 - mean_squared_error: 453.0331\n",
      "Epoch 26/100\n",
      "32525/32525 [==============================] - 95s 3ms/step - loss: 435.9600 - mean_squared_error: 435.9600\n",
      "Epoch 27/100\n",
      "32525/32525 [==============================] - 94s 3ms/step - loss: 433.0321 - mean_squared_error: 433.0321\n",
      "Epoch 28/100\n",
      "32525/32525 [==============================] - 94s 3ms/step - loss: 432.4233 - mean_squared_error: 432.4233\n",
      "Epoch 29/100\n",
      "32525/32525 [==============================] - 95s 3ms/step - loss: 409.7273 - mean_squared_error: 409.7273\n",
      "Epoch 30/100\n",
      "32525/32525 [==============================] - 96s 3ms/step - loss: 408.1784 - mean_squared_error: 408.1784\n",
      "Epoch 31/100\n",
      "32525/32525 [==============================] - 94s 3ms/step - loss: 401.6170 - mean_squared_error: 401.6170\n",
      "Epoch 32/100\n",
      "32525/32525 [==============================] - 93s 3ms/step - loss: 406.8740 - mean_squared_error: 406.8740\n",
      "Epoch 33/100\n",
      "32525/32525 [==============================] - 94s 3ms/step - loss: 408.6530 - mean_squared_error: 408.6530\n",
      "Epoch 34/100\n",
      "32525/32525 [==============================] - 95s 3ms/step - loss: 417.3818 - mean_squared_error: 417.3818\n",
      "Epoch 35/100\n",
      "32525/32525 [==============================] - 93s 3ms/step - loss: 406.3614 - mean_squared_error: 406.3614\n",
      "Epoch 36/100\n",
      "32525/32525 [==============================] - 96s 3ms/step - loss: 400.9269 - mean_squared_error: 400.9269\n",
      "Epoch 37/100\n",
      "32525/32525 [==============================] - 94s 3ms/step - loss: 405.9675 - mean_squared_error: 405.9675\n",
      "Epoch 38/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 399.8613 - mean_squared_error: 399.8613\n",
      "Epoch 39/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 395.7208 - mean_squared_error: 395.7208\n",
      "Epoch 40/100\n",
      "32525/32525 [==============================] - 87s 3ms/step - loss: 396.5463 - mean_squared_error: 396.5463\n",
      "Epoch 41/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 408.4216 - mean_squared_error: 408.4216\n",
      "Epoch 42/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 386.1835 - mean_squared_error: 386.1835\n",
      "Epoch 43/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 398.5447 - mean_squared_error: 398.5447\n",
      "Epoch 44/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 383.9166 - mean_squared_error: 383.9166\n",
      "Epoch 45/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 384.1850 - mean_squared_error: 384.1850\n",
      "Epoch 46/100\n",
      "32525/32525 [==============================] - 94s 3ms/step - loss: 383.3620 - mean_squared_error: 383.3620\n",
      "Epoch 47/100\n",
      "32525/32525 [==============================] - 95s 3ms/step - loss: 387.6525 - mean_squared_error: 387.6525\n",
      "Epoch 48/100\n",
      "32525/32525 [==============================] - 96s 3ms/step - loss: 377.4432 - mean_squared_error: 377.4432\n",
      "Epoch 49/100\n",
      "32525/32525 [==============================] - 94s 3ms/step - loss: 374.5277 - mean_squared_error: 374.5277\n",
      "Epoch 50/100\n",
      "32525/32525 [==============================] - 93s 3ms/step - loss: 388.1396 - mean_squared_error: 388.1396\n",
      "Epoch 51/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 375.0392 - mean_squared_error: 375.0392\n",
      "Epoch 52/100\n",
      "32525/32525 [==============================] - 93s 3ms/step - loss: 379.3025 - mean_squared_error: 379.3025\n",
      "Epoch 53/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 372.3961 - mean_squared_error: 372.3961\n",
      "Epoch 54/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 371.1719 - mean_squared_error: 371.1719 1s - loss: 374.2308 - mean_squared_error:  - ETA: 1s\n",
      "Epoch 55/100\n",
      "32525/32525 [==============================] - 93s 3ms/step - loss: 366.5580 - mean_squared_error: 366.5580\n",
      "Epoch 56/100\n",
      "32525/32525 [==============================] - 101s 3ms/step - loss: 384.9248 - mean_squared_error: 384.9248\n",
      "Epoch 57/100\n",
      "32525/32525 [==============================] - 115s 4ms/step - loss: 372.6350 - mean_squared_error: 372.6350\n",
      "Epoch 58/100\n",
      "32525/32525 [==============================] - 107s 3ms/step - loss: 368.3514 - mean_squared_error: 368.3514\n",
      "Epoch 59/100\n",
      "32525/32525 [==============================] - 105s 3ms/step - loss: 371.5500 - mean_squared_error: 371.5500\n",
      "Epoch 60/100\n",
      "32525/32525 [==============================] - 94s 3ms/step - loss: 355.9093 - mean_squared_error: 355.9093\n",
      "Epoch 61/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 380.8225 - mean_squared_error: 380.8225\n",
      "Epoch 62/100\n",
      "32525/32525 [==============================] - 97s 3ms/step - loss: 359.9308 - mean_squared_error: 359.9308\n",
      "Epoch 63/100\n",
      "32525/32525 [==============================] - 117s 4ms/step - loss: 359.8539 - mean_squared_error: 359.8539\n",
      "Epoch 64/100\n",
      "32525/32525 [==============================] - 113s 3ms/step - loss: 360.1532 - mean_squared_error: 360.1532\n",
      "Epoch 65/100\n",
      "32525/32525 [==============================] - 118s 4ms/step - loss: 352.5389 - mean_squared_error: 352.5389\n",
      "Epoch 66/100\n",
      "32525/32525 [==============================] - 117s 4ms/step - loss: 362.1813 - mean_squared_error: 362.1813\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32525/32525 [==============================] - 107s 3ms/step - loss: 365.9749 - mean_squared_error: 365.9749\n",
      "Epoch 68/100\n",
      "32525/32525 [==============================] - 102s 3ms/step - loss: 357.8987 - mean_squared_error: 357.8987\n",
      "Epoch 69/100\n",
      "32525/32525 [==============================] - 102s 3ms/step - loss: 354.0570 - mean_squared_error: 354.0570\n",
      "Epoch 70/100\n",
      "32525/32525 [==============================] - 103s 3ms/step - loss: 361.8463 - mean_squared_error: 361.8463\n",
      "Epoch 71/100\n",
      "32525/32525 [==============================] - 113s 3ms/step - loss: 357.6417 - mean_squared_error: 357.6417\n",
      "Epoch 72/100\n",
      "32525/32525 [==============================] - 137s 4ms/step - loss: 350.3591 - mean_squared_error: 350.3591\n",
      "Epoch 73/100\n",
      "32525/32525 [==============================] - 113s 3ms/step - loss: 360.3193 - mean_squared_error: 360.3193\n",
      "Epoch 74/100\n",
      "32525/32525 [==============================] - 91s 3ms/step - loss: 347.8130 - mean_squared_error: 347.8130\n",
      "Epoch 75/100\n",
      "32525/32525 [==============================] - 102s 3ms/step - loss: 343.0256 - mean_squared_error: 343.0256\n",
      "Epoch 76/100\n",
      "32525/32525 [==============================] - 103s 3ms/step - loss: 340.5165 - mean_squared_error: 340.5165\n",
      "Epoch 77/100\n",
      "32525/32525 [==============================] - 100s 3ms/step - loss: 350.2078 - mean_squared_error: 350.2078\n",
      "Epoch 78/100\n",
      "32525/32525 [==============================] - 101s 3ms/step - loss: 340.7248 - mean_squared_error: 340.7248\n",
      "Epoch 79/100\n",
      "32525/32525 [==============================] - 103s 3ms/step - loss: 338.1807 - mean_squared_error: 338.1807\n",
      "Epoch 80/100\n",
      "32525/32525 [==============================] - 118s 4ms/step - loss: 351.1756 - mean_squared_error: 351.1756\n",
      "Epoch 81/100\n",
      "32525/32525 [==============================] - 102s 3ms/step - loss: 337.1223 - mean_squared_error: 337.12230s - loss: 336.9779 - mean_squared_error: \n",
      "Epoch 82/100\n",
      "32525/32525 [==============================] - 100s 3ms/step - loss: 344.3523 - mean_squared_error: 344.3523\n",
      "Epoch 83/100\n",
      "32525/32525 [==============================] - 107s 3ms/step - loss: 349.7595 - mean_squared_error: 349.7595\n",
      "Epoch 84/100\n",
      "32525/32525 [==============================] - 107s 3ms/step - loss: 335.5034 - mean_squared_error: 335.5034\n",
      "Epoch 85/100\n",
      "32525/32525 [==============================] - 95s 3ms/step - loss: 336.5109 - mean_squared_error: 336.5109\n",
      "Epoch 86/100\n",
      "32525/32525 [==============================] - 94s 3ms/step - loss: 330.8883 - mean_squared_error: 330.8883\n",
      "Epoch 87/100\n",
      "32525/32525 [==============================] - 93s 3ms/step - loss: 336.9942 - mean_squared_error: 336.9942\n",
      "Epoch 88/100\n",
      "32525/32525 [==============================] - 96s 3ms/step - loss: 329.1720 - mean_squared_error: 329.1720\n",
      "Epoch 89/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 334.6963 - mean_squared_error: 334.6963\n",
      "Epoch 90/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 329.6742 - mean_squared_error: 329.6742\n",
      "Epoch 91/100\n",
      "32525/32525 [==============================] - 93s 3ms/step - loss: 346.4774 - mean_squared_error: 346.4774\n",
      "Epoch 92/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 329.4352 - mean_squared_error: 329.4352\n",
      "Epoch 93/100\n",
      "32525/32525 [==============================] - 94s 3ms/step - loss: 330.3687 - mean_squared_error: 330.3687\n",
      "Epoch 94/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 327.8777 - mean_squared_error: 327.8777\n",
      "Epoch 95/100\n",
      "32525/32525 [==============================] - 92s 3ms/step - loss: 338.7802 - mean_squared_error: 338.7802\n",
      "Epoch 96/100\n",
      "32525/32525 [==============================] - 99s 3ms/step - loss: 312.6576 - mean_squared_error: 312.6576\n",
      "Epoch 97/100\n",
      "32525/32525 [==============================] - 99s 3ms/step - loss: 329.7207 - mean_squared_error: 329.7207\n",
      "Epoch 98/100\n",
      "32525/32525 [==============================] - 93s 3ms/step - loss: 316.5820 - mean_squared_error: 316.5820\n",
      "Epoch 99/100\n",
      "32525/32525 [==============================] - 95s 3ms/step - loss: 322.0938 - mean_squared_error: 322.0938 0s - loss: 321.7439 - mean\n",
      "Epoch 100/100\n",
      "32525/32525 [==============================] - 94s 3ms/step - loss: 320.5838 - mean_squared_error: 320.5838\n",
      "Training took 9920.480637073517 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    batch_size=2, \n",
    "    epochs=100, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training took {} seconds\".format(\n",
    "    time.time() - start\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 17.2599058004813\n",
      "Test error: 22.179094912040828\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(X_train)\n",
    "print(\"Training error: {}\".format(\n",
    "    np.sqrt(mean_squared_error(y_train, pred_train))\n",
    "))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(\"Test error: {}\".format(\n",
    "    np.sqrt(mean_squared_error(y_test, pred))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = os.path.join(\"..\", \"results\")\n",
    "\n",
    "if not os.path.exists(RESULTS):\n",
    "    os.makedirs(RESULTS)\n",
    "    \n",
    "filename = os.path.join(RESULTS, \"tensorflow_model.h5\")\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the model and run live predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
