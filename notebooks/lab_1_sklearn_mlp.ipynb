{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptrons with scikit-learn\n",
    "\n",
    "**XBUS-512: Introduction to AI and Deep Learning**\n",
    "\n",
    "In this exercise, we will see how to build a preliminary neural model using the familiar scikit-learn library. While scikit-learn is not a deep learning library, it does provide basic implementations of the multilayer perceptron (MLP) for both classification and regression.\n",
    "\n",
    "\n",
    "Thanks to [this team](https://github.com/Wall-eSociety/CommentVolumeML) for figuring out the labels for this dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import zipfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(url, fname):\n",
    "    \"\"\"\n",
    "    Helper method to retreive the data from the UCI ML Repository.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    outpath  = os.path.abspath(fname)\n",
    "    with open(outpath, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    return outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and unzip the data\n",
    "\n",
    "URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00363/Dataset.zip\"\n",
    "ZIPPED_FILES = \"facebook_data.zip\"\n",
    "UNZIPPED_FILES = \"facebook_data\"\n",
    "\n",
    "zipped_data = fetch_data(URL, os.path.join(\"..\", \"fixtures\", ZIPPED_FILES))\n",
    "\n",
    "with zipfile.ZipFile(os.path.join(\"..\", \"fixtures\", ZIPPED_FILES), \"r\") as zfiles:\n",
    "    zfiles.extractall(os.path.join(\"..\", \"fixtures\", UNZIPPED_FILES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>views</th>\n",
       "      <th>returns</th>\n",
       "      <th>category</th>\n",
       "      <th>derived_1</th>\n",
       "      <th>derived_2</th>\n",
       "      <th>derived_3</th>\n",
       "      <th>derived_4</th>\n",
       "      <th>derived_5</th>\n",
       "      <th>derived_6</th>\n",
       "      <th>...</th>\n",
       "      <th>friday_post</th>\n",
       "      <th>saturday_post</th>\n",
       "      <th>sunday_base</th>\n",
       "      <th>monday_base</th>\n",
       "      <th>tuesday_base</th>\n",
       "      <th>wednesday_base</th>\n",
       "      <th>thursday_base</th>\n",
       "      <th>friday_base</th>\n",
       "      <th>saturday_base</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.131200e+04</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>8.131200e+04</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "      <td>81312.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.313921e+06</td>\n",
       "      <td>4667.704336</td>\n",
       "      <td>4.475377e+04</td>\n",
       "      <td>24.255633</td>\n",
       "      <td>0.707190</td>\n",
       "      <td>464.665781</td>\n",
       "      <td>55.728933</td>\n",
       "      <td>35.392255</td>\n",
       "      <td>67.588653</td>\n",
       "      <td>0.143361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146153</td>\n",
       "      <td>0.136954</td>\n",
       "      <td>0.141049</td>\n",
       "      <td>0.133400</td>\n",
       "      <td>0.138417</td>\n",
       "      <td>0.145477</td>\n",
       "      <td>0.155180</td>\n",
       "      <td>0.144997</td>\n",
       "      <td>0.141480</td>\n",
       "      <td>7.190611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.804951e+06</td>\n",
       "      <td>20561.261034</td>\n",
       "      <td>1.109279e+05</td>\n",
       "      <td>19.949156</td>\n",
       "      <td>12.169748</td>\n",
       "      <td>520.925523</td>\n",
       "      <td>85.243275</td>\n",
       "      <td>67.043844</td>\n",
       "      <td>82.836764</td>\n",
       "      <td>7.819979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353262</td>\n",
       "      <td>0.343801</td>\n",
       "      <td>0.348075</td>\n",
       "      <td>0.340008</td>\n",
       "      <td>0.345340</td>\n",
       "      <td>0.352583</td>\n",
       "      <td>0.362078</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>0.348518</td>\n",
       "      <td>36.049374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.673400e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.980000e+02</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>5.190751</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.032349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.929110e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.045000e+03</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>22.794183</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>32.565168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.204214e+06</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>5.026400e+04</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>717.000000</td>\n",
       "      <td>71.791489</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>102.060861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.869723e+08</td>\n",
       "      <td>186370.000000</td>\n",
       "      <td>6.089942e+06</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>1311.000000</td>\n",
       "      <td>2438.000000</td>\n",
       "      <td>1693.500000</td>\n",
       "      <td>1693.500000</td>\n",
       "      <td>743.091650</td>\n",
       "      <td>1311.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1966.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              likes          views       returns      category     derived_1  \\\n",
       "count  8.131200e+04   81312.000000  8.131200e+04  81312.000000  81312.000000   \n",
       "mean   1.313921e+06    4667.704336  4.475377e+04     24.255633      0.707190   \n",
       "std    6.804951e+06   20561.261034  1.109279e+05     19.949156     12.169748   \n",
       "min    3.600000e+01       0.000000  0.000000e+00      1.000000      0.000000   \n",
       "25%    3.673400e+04       0.000000  6.980000e+02      9.000000      0.000000   \n",
       "50%    2.929110e+05       0.000000  7.045000e+03     18.000000      0.000000   \n",
       "75%    1.204214e+06      99.000000  5.026400e+04     32.000000      0.000000   \n",
       "max    4.869723e+08  186370.000000  6.089942e+06    106.000000   1311.000000   \n",
       "\n",
       "          derived_2     derived_3     derived_4     derived_5     derived_6  \\\n",
       "count  81312.000000  81312.000000  81312.000000  81312.000000  81312.000000   \n",
       "mean     464.665781     55.728933     35.392255     67.588653      0.143361   \n",
       "std      520.925523     85.243275     67.043844     82.836764      7.819979   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       47.000000      5.190751      2.000000      8.032349      0.000000   \n",
       "50%      251.000000     22.794183     13.000000     32.565168      0.000000   \n",
       "75%      717.000000     71.791489     42.000000    102.060861      0.000000   \n",
       "max     2438.000000   1693.500000   1693.500000    743.091650   1311.000000   \n",
       "\n",
       "       ...   friday_post  saturday_post   sunday_base   monday_base  \\\n",
       "count  ...  81312.000000   81312.000000  81312.000000  81312.000000   \n",
       "mean   ...      0.146153       0.136954      0.141049      0.133400   \n",
       "std    ...      0.353262       0.343801      0.348075      0.340008   \n",
       "min    ...      0.000000       0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000       0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000       0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000       0.000000      0.000000      0.000000   \n",
       "max    ...      1.000000       1.000000      1.000000      1.000000   \n",
       "\n",
       "       tuesday_base  wednesday_base  thursday_base   friday_base  \\\n",
       "count  81312.000000    81312.000000   81312.000000  81312.000000   \n",
       "mean       0.138417        0.145477       0.155180      0.144997   \n",
       "std        0.345340        0.352583       0.362078      0.352100   \n",
       "min        0.000000        0.000000       0.000000      0.000000   \n",
       "25%        0.000000        0.000000       0.000000      0.000000   \n",
       "50%        0.000000        0.000000       0.000000      0.000000   \n",
       "75%        0.000000        0.000000       0.000000      0.000000   \n",
       "max        1.000000        1.000000       1.000000      1.000000   \n",
       "\n",
       "       saturday_base        target  \n",
       "count   81312.000000  81312.000000  \n",
       "mean        0.141480      7.190611  \n",
       "std         0.348518     36.049374  \n",
       "min         0.000000      0.000000  \n",
       "25%         0.000000      0.000000  \n",
       "50%         0.000000      0.000000  \n",
       "75%         0.000000      3.000000  \n",
       "max         1.000000   1966.000000  \n",
       "\n",
       "[8 rows x 54 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    os.path.join(\n",
    "        \"..\", \n",
    "        \"fixtures\", \n",
    "        UNZIPPED_FILES, \n",
    "        \"Dataset\", \n",
    "        \"Training\", \n",
    "        \"Features_Variant_2.csv\"\n",
    "    ),\n",
    "    header=None\n",
    ")\n",
    "data.columns = [\n",
    "    \"likes\", \"views\", \"returns\", \"category\", \"derived_1\", \"derived_2\", \"derived_3\",\n",
    "    \"derived_4\", \"derived_5\", \"derived_6\", \"derived_7\", \"derived_8\", \"derived_9\",\n",
    "    \"derived_10\", \"derived_11\", \"derived_12\", \"derived_13\", \"derived_14\", \"derived_15\", \n",
    "    \"derived_16\", \"derived_17\", \"derived_18\", \"derived_19\", \"derived_20\", \"derived_21\",\n",
    "    \"derived_22\", \"derived_23\", \"derived_24\", \"derived_25\", \"cc_1\", \"cc_2\", \"cc_3\",\n",
    "    \"cc_4\", \"cc_5\", \"base_time\", \"length\", \"shares\", \"status\", \"h_local\", \"sunday_post\",\n",
    "    \"monday_post\", \"tuesday_post\", \"wednesday_post\", \"thursday_post\", \"friday_post\",\n",
    "    \"saturday_post\", \"sunday_base\", \"monday_base\", \"tuesday_base\", \"wednesday_base\",\n",
    "    \"thursday_base\", \"friday_base\", \"saturday_base\", \"target\"\n",
    "]\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_regression(dataframe):\n",
    "    \"\"\"\n",
    "    Prepare the data for a regression problem where we will attempt\n",
    "    to regress the number of comments that a Facebook post will get\n",
    "    given other features of the data.\n",
    "    \n",
    "    Returns a tuple containing an nd array of features (X)\n",
    "    and a 1d array for the target (y)\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        \"likes\", \"views\", \"returns\", \"category\", \"derived_1\", \"derived_2\", \"derived_3\",\n",
    "        \"derived_4\", \"derived_5\", \"derived_6\", \"derived_7\", \"derived_8\", \"derived_9\",\n",
    "        \"derived_10\", \"derived_11\", \"derived_12\", \"derived_13\", \"derived_14\", \"derived_15\", \n",
    "        \"derived_16\", \"derived_17\", \"derived_18\", \"derived_19\", \"derived_20\", \"derived_21\",\n",
    "        \"derived_22\", \"derived_23\", \"derived_24\", \"derived_25\", \"cc_1\", \"cc_2\", \"cc_3\",\n",
    "        \"cc_4\", \"cc_5\", \"base_time\", \"length\", \"shares\", \"status\", \"h_local\", \"sunday_post\",\n",
    "        \"monday_post\", \"tuesday_post\", \"wednesday_post\", \"thursday_post\", \"friday_post\",\n",
    "        \"saturday_post\", \"sunday_base\", \"monday_base\", \"tuesday_base\", \"wednesday_base\",\n",
    "        \"thursday_base\", \"friday_base\", \"saturday_base\"     \n",
    "    ]\n",
    "    target = \"target\"\n",
    "    \n",
    "    # MLP is sensitive to feature scaling!\n",
    "    X = MinMaxScaler().fit_transform(dataframe[features].values)\n",
    "    y = dataframe[target].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def prepare_for_classification(dataframe):\n",
    "    \"\"\"\n",
    "    Prepare the data for a classification problem where we will attempt\n",
    "    to predict the category of a Facebook post given features of the data.\n",
    "    \n",
    "    Returns a tuple containing an nd array of features (X)\n",
    "    and a 1d array for the target (y)\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        \"likes\", \"views\", \"returns\", \"derived_1\", \"derived_2\", \"derived_3\",\n",
    "        \"derived_4\", \"derived_5\", \"derived_6\", \"derived_7\", \"derived_8\", \"derived_9\",\n",
    "        \"derived_10\", \"derived_11\", \"derived_12\", \"derived_13\", \"derived_14\", \"derived_15\", \n",
    "        \"derived_16\", \"derived_17\", \"derived_18\", \"derived_19\", \"derived_20\", \"derived_21\",\n",
    "        \"derived_22\", \"derived_23\", \"derived_24\", \"derived_25\", \"cc_1\", \"cc_2\", \"cc_3\",\n",
    "        \"cc_4\", \"cc_5\", \"base_time\", \"length\", \"shares\", \"status\", \"h_local\", \"sunday_post\",\n",
    "        \"monday_post\", \"tuesday_post\", \"wednesday_post\", \"thursday_post\", \"friday_post\",\n",
    "        \"saturday_post\", \"sunday_base\", \"monday_base\", \"tuesday_base\", \"wednesday_base\",\n",
    "        \"thursday_base\", \"friday_base\", \"saturday_base\", \"target\"     \n",
    "    ]\n",
    "    target = \"category\"\n",
    "    \n",
    "    # MLP is sensitive to feature scaling!\n",
    "    X = MinMaxScaler().fit_transform(dataframe[features].values)\n",
    "    y = dataframe[target].values\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data and break in to training and test splits\n",
    "X, y = prepare_for_regression(data)\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the model, set hyperparameters, and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 396.53177614\n",
      "Iteration 2, loss = 341.45866439\n",
      "Iteration 3, loss = 316.14030191\n",
      "Iteration 4, loss = 294.82102691\n",
      "Iteration 5, loss = 288.69418552\n",
      "Iteration 6, loss = 283.89115844\n",
      "Iteration 7, loss = 278.11670092\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=(100, 50, 25), \n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    batch_size=2,\n",
    "    max_iter=100,\n",
    "    verbose=True\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training took {} seconds\".format(\n",
    "    time.time() - start\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train)\n",
    "print(\"Training error: {}\".format(\n",
    "    np.sqrt(mean_squared_error(y_train, pred_train))\n",
    "))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(\"Test error: {}\".format(\n",
    "    np.sqrt(mean_squared_error(y_test, pred))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results using Yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = PredictionError(model)\n",
    "\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ResidualsPlot(model)\n",
    "\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = os.path.join(\"..\", \"results\")\n",
    "\n",
    "if not os.path.exists(RESULTS):\n",
    "    os.makedirs(RESULTS)\n",
    "    \n",
    "filename = os.path.join(RESULTS, \"sklearn_model.pkl\")\n",
    "pickle.dump(model, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the model and run live predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickled_model = pickle.load(open(filename, \"rb\"))\n",
    "new_prediction = loaded_model.predict(X_test[0])\n",
    "print(\"Predicted value: \", new_prediction)\n",
    "print(\"Actual value: \", y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways from our scikit-learn prototype:\n",
    "    - sklearn API is convenient\n",
    "    - can tune some hyperparams\n",
    "    - easy to visualize & diagnose with Yellowbrick\n",
    "    - tough to tune for overfit model... would be nice to have dropout, for instance\n",
    "    - sloooooow\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
