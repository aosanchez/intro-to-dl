{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "**XBUS-512: Introduction to AI and Deep Learning**\n",
    "\n",
    "In this exercise, we will see how to build a generative adversarial network using the MNIST digits dataset. \n",
    "\n",
    "*Note: this lab is inspired by [this blog post](https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/) by Jason Brownlee.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.layers import Dense, Conv2D\n",
    "from numpy.random import randn, randint\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Reshape, Flatten\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras.layers import LeakyReLU, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store path\n",
    "\n",
    "This is the path where we'll store the results of our model and our model evaluation plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = os.path.join(\"..\", \"results\")\n",
    "\n",
    "if not os.path.exists(RESULTS):\n",
    "    os.makedirs(RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data \n",
    "This will also download the data if it has not been already.\n",
    "\n",
    "The data consists of 70,000 images of handwritten digits, each represented as a 28Ã—28 pixel grayscale image. The target column (`y`) is the label of for each image, represented as integers between 0 and 9.\n",
    "\n",
    "The `load_real_samples` function will load the data from Keras, split it into 60,000/10,000 for training and testing, scale the data between 0 and 1, and expand the input data dimensionality from 2 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "    \"\"\"\n",
    "    Load and prepare mnist training images\n",
    "    \"\"\"\n",
    "    (X_train, _), (_, _) = load_data()\n",
    "    X = np.expand_dims(X_train, axis=-1)\n",
    "    X = X.astype(\"float32\") / 255.0\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1363f2080>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can inspect the images using matplotlib:\n",
    "X_train = load_real_samples()\n",
    "plt.imshow(X_train[10], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Discriminator\n",
    "\n",
    "First we will create a discriminator, which will learn how to distinguish real images from synthetic images.\n",
    "\n",
    "Our discriminator will have two convolutional layers of 64 filters each, a convolutional window (kernel) of 3, and a stride of 2. The output layer uses a sigmoidal activation function to perform binary classification (real image or fake image), minimizing the binary cross entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(input_shape=(28, 28, 1)):\n",
    "    \"\"\"\n",
    "    Define the standalone discriminator model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(\n",
    "        64, \n",
    "        (3, 3), \n",
    "        strides=(2, 2), \n",
    "        padding=\"same\", \n",
    "        input_shape=input_shape\n",
    "    ))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(\n",
    "        64, \n",
    "        (3, 3), \n",
    "        strides=(2, 2), \n",
    "        padding=\"same\"\n",
    "    ))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\", \n",
    "        metrics=[\"accuracy\"],\n",
    "        optimizer=opt\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generator\n",
    "\n",
    "Next we will create a generator, which will learn how to create new \"handwritten\" digits.\n",
    "\n",
    "The `kernel` specifies the height & width of the 2D convolutional window.\n",
    "\n",
    "The `strides` are the strides of the convolution along the height & width.\n",
    "\n",
    "The `padding` can be one of \"valid\" or \"same\" (case-insensitive); \"valid\" means no padding and \"same\" results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n",
    "\n",
    "The `activation` is the activation function to use (we're using sigmoid here). See `keras.activations` for more options.\n",
    "\n",
    "The `latent_dimensions` are the number of latent dimensions in the deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dimensions):\n",
    "    \"\"\"\n",
    "    Define the standalone generator model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    n_nodes = 128 * 7 * 7\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dimensions))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(Conv2DTranspose(\n",
    "        128, \n",
    "        (4,4), \n",
    "        strides=(2,2), \n",
    "        padding=\"same\"\n",
    "    ))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(\n",
    "        128, \n",
    "        (4,4), \n",
    "        strides=(2,2), \n",
    "        padding=\"same\"\n",
    "    ))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(\n",
    "        1, \n",
    "        (7,7), \n",
    "        activation=\"sigmoid\", \n",
    "        padding=\"same\"\n",
    "    ))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(generator, discriminator):\n",
    "    \"\"\"\n",
    "    Define the combined generator and discriminator\n",
    "    model, for updating the generator\n",
    "    \"\"\"\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\", \n",
    "        optimizer=opt\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(X, n_samples):\n",
    "    \"\"\"\n",
    "    Select real samples at random and assign a \"1\" class\n",
    "    \"\"\"\n",
    "    ix = randint(0, X.shape[0], n_samples)\n",
    "    X_test = X[ix]\n",
    "    y_test = np.ones((n_samples, 1))\n",
    "    return X_test, y_test\n",
    "\n",
    "def generate_latent_points(n_samples, latent_dimensions):\n",
    "    \"\"\"\n",
    "    Generate points in latent space as input for the generator\n",
    "    \"\"\"\n",
    "    X_input = randn(latent_dimensions * n_samples)\n",
    "    X_input = X_input.reshape(n_samples, latent_dimensions)\n",
    "    return X_input\n",
    "\n",
    "def generate_fake_samples(n_samples, latent_dimensions, generator):\n",
    "    \"\"\"\n",
    "    Use the generator to generate fake examples with \"0\" class labels\n",
    "    \"\"\"\n",
    "    X_input = generate_latent_points(n_samples, latent_dimensions)\n",
    "    X = generator.predict(X_input)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(examples, epoch, n=10):\n",
    "    \"\"\"\n",
    "    Create and save a plot of generated images\n",
    "    \"\"\"\n",
    "    for idx in range(n * n):\n",
    "        plt.subplot(n, n, 1 + idx)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(examples[idx, :, :, 0], cmap=\"gray_r\")\n",
    "        \n",
    "    filename = os.path.join(STORE_PATH, \"generated_plot_epoch{}.png\".format(epoch + 1))\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def summarize_performance(\n",
    "    epoch, \n",
    "    generator, \n",
    "    discriminator, \n",
    "    X, \n",
    "    latent_dimensions, \n",
    "    n_samples=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate the discriminator, plot generated images, and \n",
    "    save generator model\n",
    "    \"\"\"\n",
    "    X_real, y_real = generate_real_samples(X, n_samples)\n",
    "    _, acc_real = discriminator.evaluate(X_real, y_real, verbose=0)\n",
    "    X_fake, y_fake = generate_fake_samples(n_samples, latent_dimensions, generator)\n",
    "    _, acc_fake = discriminator.evaluate(X_fake, y_fake, verbose=0)\n",
    "    \n",
    "    print(\">>>Discriminator's accuracy for real: {}, fake: {}\".format(\n",
    "        acc_real*100, acc_fake*100\n",
    "    ))\n",
    "    save_plot(X_fake, epoch)\n",
    "    \n",
    "    filename = os.path.join(STORE_PATH, \"generator_model_epoch{}.h5\".format(epoch + 1))\n",
    "    generator.save(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    generator, \n",
    "    discriminator, \n",
    "    gan, \n",
    "    X, \n",
    "    latent_dimensions, \n",
    "    n_epochs=30, \n",
    "    n_batch=256\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the GAN\n",
    "    \"\"\"\n",
    "    batches_per_epoch = int(X.shape[0] / n_batch)\n",
    "    split = int(n_batch / 2)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in range(batches_per_epoch):\n",
    "\n",
    "            X_real, y_real = generate_real_samples(X, split)\n",
    "            X_fake, y_fake = generate_fake_samples(split, latent_dimensions, generator)\n",
    "\n",
    "            X_both, y_both = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
    "            discriminator_loss, _ = discriminator.train_on_batch(X_both, y_both)\n",
    "            \n",
    "            X_gan = generate_latent_points(n_batch, latent_dimensions)\n",
    "            y_gan = np.ones((n_batch, 1))\n",
    "            generator_loss = gan.train_on_batch(X_gan, y_gan)\n",
    "            print(\"Iteration {}, {}/{}, discriminator={:.2f}, generator={:.2f}\".format(\n",
    "                epoch + 1, \n",
    "                batch + 1, \n",
    "                batches_per_epoch, \n",
    "                discriminator_loss, \n",
    "                generator_loss\n",
    "            ))\n",
    "\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            summarize_performance(epoch, generator, discriminator, X, latent_dimensions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the Compiled Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimensions = 100\n",
    "\n",
    "discriminator = define_discriminator()\n",
    "generator = define_generator(latent_dimensions)\n",
    "gan = define_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 3137      \n",
      "=================================================================\n",
      "Total params: 40,705\n",
      "Trainable params: 0\n",
      "Non-trainable params: 40,705\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 1)         6273      \n",
      "=================================================================\n",
      "Total params: 1,164,289\n",
      "Trainable params: 1,164,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 28, 28, 1)         1164289   \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 1)                 40705     \n",
      "=================================================================\n",
      "Total params: 1,204,994\n",
      "Trainable params: 1,164,289\n",
      "Non-trainable params: 40,705\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, 1/234, discriminator=0.72, generator=0.66\n",
      "Iteration 1, 2/234, discriminator=0.71, generator=0.67\n",
      "Iteration 1, 3/234, discriminator=0.70, generator=0.69\n",
      "Iteration 1, 4/234, discriminator=0.70, generator=0.71\n",
      "Iteration 1, 5/234, discriminator=0.69, generator=0.73\n",
      "Iteration 1, 6/234, discriminator=0.68, generator=0.75\n",
      "Iteration 1, 7/234, discriminator=0.67, generator=0.76\n",
      "Iteration 1, 8/234, discriminator=0.66, generator=0.78\n",
      "Iteration 1, 9/234, discriminator=0.66, generator=0.79\n",
      "Iteration 1, 10/234, discriminator=0.65, generator=0.81\n",
      "Iteration 1, 11/234, discriminator=0.64, generator=0.82\n",
      "Iteration 1, 12/234, discriminator=0.64, generator=0.82\n",
      "Iteration 1, 13/234, discriminator=0.65, generator=0.82\n",
      "Iteration 1, 14/234, discriminator=0.65, generator=0.80\n",
      "Iteration 1, 15/234, discriminator=0.65, generator=0.78\n",
      "Iteration 1, 16/234, discriminator=0.66, generator=0.75\n",
      "Iteration 1, 17/234, discriminator=0.66, generator=0.73\n",
      "Iteration 1, 18/234, discriminator=0.66, generator=0.72\n",
      "Iteration 1, 19/234, discriminator=0.66, generator=0.71\n",
      "Iteration 1, 20/234, discriminator=0.66, generator=0.70\n",
      "Iteration 1, 21/234, discriminator=0.65, generator=0.70\n",
      "Iteration 1, 22/234, discriminator=0.65, generator=0.70\n",
      "Iteration 1, 23/234, discriminator=0.64, generator=0.69\n",
      "Iteration 1, 24/234, discriminator=0.64, generator=0.69\n",
      "Iteration 1, 25/234, discriminator=0.63, generator=0.69\n",
      "Iteration 1, 26/234, discriminator=0.62, generator=0.69\n",
      "Iteration 1, 27/234, discriminator=0.62, generator=0.69\n",
      "Iteration 1, 28/234, discriminator=0.61, generator=0.69\n",
      "Iteration 1, 29/234, discriminator=0.60, generator=0.69\n",
      "Iteration 1, 30/234, discriminator=0.59, generator=0.69\n",
      "Iteration 1, 31/234, discriminator=0.59, generator=0.70\n",
      "Iteration 1, 32/234, discriminator=0.57, generator=0.70\n",
      "Iteration 1, 33/234, discriminator=0.57, generator=0.70\n",
      "Iteration 1, 34/234, discriminator=0.55, generator=0.70\n",
      "Iteration 1, 35/234, discriminator=0.54, generator=0.70\n",
      "Iteration 1, 36/234, discriminator=0.53, generator=0.70\n",
      "Iteration 1, 37/234, discriminator=0.53, generator=0.70\n",
      "Iteration 1, 38/234, discriminator=0.52, generator=0.70\n",
      "Iteration 1, 39/234, discriminator=0.50, generator=0.70\n",
      "Iteration 1, 40/234, discriminator=0.50, generator=0.71\n",
      "Iteration 1, 41/234, discriminator=0.48, generator=0.71\n",
      "Iteration 1, 42/234, discriminator=0.47, generator=0.71\n",
      "Iteration 1, 43/234, discriminator=0.47, generator=0.71\n",
      "Iteration 1, 44/234, discriminator=0.46, generator=0.71\n",
      "Iteration 1, 45/234, discriminator=0.45, generator=0.71\n",
      "Iteration 1, 46/234, discriminator=0.44, generator=0.72\n",
      "Iteration 1, 47/234, discriminator=0.43, generator=0.72\n",
      "Iteration 1, 48/234, discriminator=0.42, generator=0.72\n",
      "Iteration 1, 49/234, discriminator=0.41, generator=0.73\n",
      "Iteration 1, 50/234, discriminator=0.42, generator=0.73\n",
      "Iteration 1, 51/234, discriminator=0.40, generator=0.73\n",
      "Iteration 1, 52/234, discriminator=0.40, generator=0.74\n",
      "Iteration 1, 53/234, discriminator=0.39, generator=0.74\n",
      "Iteration 1, 54/234, discriminator=0.39, generator=0.75\n",
      "Iteration 1, 55/234, discriminator=0.38, generator=0.75\n",
      "Iteration 1, 56/234, discriminator=0.37, generator=0.76\n",
      "Iteration 1, 57/234, discriminator=0.37, generator=0.76\n",
      "Iteration 1, 58/234, discriminator=0.36, generator=0.77\n",
      "Iteration 1, 59/234, discriminator=0.36, generator=0.78\n",
      "Iteration 1, 60/234, discriminator=0.35, generator=0.79\n"
     ]
    }
   ],
   "source": [
    "X = load_real_samples()\n",
    "\n",
    "train(generator, discriminator, gan, X, latent_dimensions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
