{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "**XBUS-512: Introduction to AI and Deep Learning**\n",
    "\n",
    "In this exercise, we will see how to build a generative adversarial network using the MNIST digits dataset. \n",
    "\n",
    "*Note: this lab is inspired by [this blog post](https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/) by Jason Brownlee.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.datasets.mnist import load_data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, ReLU, Reshape, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data \n",
    "This will also download the data if it has not been already.\n",
    "\n",
    "The data consists of 70,000 images of handwritten digits, each represented as a 28Ã—28 pixel grayscale image. The target column (`y`) is the label of for each image, represented as integers between 0 and 9.\n",
    "\n",
    "The `load_data` function from Keras will split the data into 60,000/10,000 for training and testing, respectively, scale the data between 0 and 1, and then using `numpy` to expand the input data dimensionality from 2 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x115888438>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can inspect the images using matplotlib:\n",
    "plt.imshow(X_train[10], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Discriminator\n",
    "\n",
    "First we will create a discriminator, which will learn how to distinguish real images from synthetic images.\n",
    "\n",
    "Our discriminator will have two convolutional layers of 64 filters each, a convolutional window (kernel) of 3, and a stride of 2. The output layer uses a sigmoidal activation function to perform binary classification (real image or fake image), minimizing the binary cross entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator():\n",
    "    \"\"\"\n",
    "    The GAN's discriminator\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        filters=64,\n",
    "        kernel=(3, 3),\n",
    "        strides=(2, 2),\n",
    "        padding=\"same\", \n",
    "        optimizer=Adam(),\n",
    "        metrics=[\"accuracy\"], \n",
    "        activation=\"sigmoid\", \n",
    "        input_shape=(28, 28, 1),\n",
    "        loss=\"binary_crossentropy\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        loss : string (default: \"binary_crossentropy\")\n",
    "            String (name of objective function), objective function or\n",
    "            `tf.keras.losses.Loss` instance.\n",
    "\n",
    "        kernel : tuple (default: (3,3))\n",
    "            Specifies the height & width of the 2D convolutional window.\n",
    "\n",
    "        strides : tuple (default: (2, 2))\n",
    "            The strides of the convolution along the height & width.\n",
    "                        \n",
    "        filters : integer (default: 64)\n",
    "            The dimensionality of the output space.\n",
    "            \n",
    "        padding : string, one of \"valid\" or \"same\" (default: \"same\")\n",
    "            One of \"valid\" or \"same\" (case-insensitive). \n",
    "            \"valid\" means no padding. \"same\" results in padding evenly\n",
    "            to the left/right or up/down of the input such that output\n",
    "            has the same height/width dimension as the input.\n",
    "\n",
    "        optimizer : keras.optimizer (default: Adam())\n",
    "            String (name of optimizer) or optimizer instance.\n",
    "            See `tf.keras.optimizers`.\n",
    "\n",
    "        metrics : list of string (default: [\"accuracy\"])\n",
    "            List of metrics to be evaluated by the model during training\n",
    "            and testing. Each of this can be a string\n",
    "            (name of a built-in function), function or a\n",
    "            `tf.keras.metrics.Metric` instance.\n",
    "            \n",
    "        activation : string (default: \"sigmoid\")\n",
    "            Activation function to use. See `keras.activations`\n",
    "            \n",
    "        input_shape : tuple (default: (28, 28, 1))\n",
    "            The input shape of the data in pixels.\n",
    "        \"\"\"\n",
    "        self.loss = loss\n",
    "        self.kernel = kernel\n",
    "        self.strides = strides\n",
    "        self.filters = filters\n",
    "        self.padding = padding\n",
    "        self.metrics = metrics\n",
    "        self.optimizer = optimizer\n",
    "        self.activation = activation\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Build the model architecture\n",
    "        \"\"\"\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(\n",
    "            self.filters,\n",
    "            self.kernel,\n",
    "            strides=self.strides,\n",
    "            padding=self.padding, \n",
    "            input_shape=self.input_shape\n",
    "        ))\n",
    "        self.model.add(ReLU())\n",
    "        self.model.add(Dropout(0.4))\n",
    "        self.model.add(Conv2D(\n",
    "            self.filters,\n",
    "            self.kernel,\n",
    "            strides=self.strides,\n",
    "            padding=self.padding\n",
    "        ))\n",
    "        self.model.add(ReLU())\n",
    "        self.model.add(Dropout(0.4))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(1, activation=self.activation))\n",
    "\n",
    "        self.model.compile(\n",
    "            loss=self.loss, \n",
    "            optimizer=self.optimizer, \n",
    "            metrics=self.metrics\n",
    "        )\n",
    "\n",
    "    def make_fakes(self, n_samples):\n",
    "        \"\"\"\n",
    "        Generate uniform random numbers in [0,1], \n",
    "        reshape into a batch of grayscale images,\n",
    "        generate fake class labels (0), and return the\n",
    "        synthetic data\n",
    "        \"\"\"\n",
    "        X = rand(28 * 28 * n_samples)\n",
    "        X = X.reshape((n_samples, 28, 28, 1))\n",
    "        y = np.zeros((n_samples, 1))\n",
    "        return X, y\n",
    "\n",
    "    def train(self, X, n_iter=100, n_batch=256):\n",
    "        \"\"\"\n",
    "        Loop over the training data, iteratively updating\n",
    "        the discriminator on real samples, generating fake samples,\n",
    "        updating the discriminator on the fakes, and summarizing\n",
    "        the model's performance\n",
    "        \"\"\"\n",
    "        half_batch = int(n_batch / 2)\n",
    "        for i in range(n_iter):\n",
    "            y = np.ones((len(X), 1))\n",
    "            _, real_acc = self.model.train_on_batch(X[:half_batch], y[:half_batch])\n",
    "            X_fake, y_fake = self.make_fakes(half_batch)\n",
    "            _, fake_acc = self.model.train_on_batch(X_fake, y_fake)\n",
    "            print(\"Iteration {}: real={} fake={}\".format(\n",
    "                i+1, real_acc*100, fake_acc*100\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 3137      \n",
      "=================================================================\n",
      "Total params: 40,705\n",
      "Trainable params: 40,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator()\n",
    "discriminator.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: real=39.0625 fake=11.71875\n",
      "Iteration 2: real=91.40625 fake=65.625\n",
      "Iteration 3: real=93.75 fake=98.4375\n",
      "Iteration 4: real=89.0625 fake=100.0\n",
      "Iteration 5: real=90.625 fake=100.0\n",
      "Iteration 6: real=85.15625 fake=100.0\n",
      "Iteration 7: real=78.90625 fake=100.0\n",
      "Iteration 8: real=80.46875 fake=100.0\n",
      "Iteration 9: real=86.71875 fake=100.0\n",
      "Iteration 10: real=92.1875 fake=100.0\n",
      "Iteration 11: real=92.1875 fake=100.0\n",
      "Iteration 12: real=98.4375 fake=100.0\n",
      "Iteration 13: real=99.21875 fake=100.0\n",
      "Iteration 14: real=100.0 fake=100.0\n",
      "Iteration 15: real=100.0 fake=100.0\n",
      "Iteration 16: real=100.0 fake=100.0\n",
      "Iteration 17: real=100.0 fake=100.0\n",
      "Iteration 18: real=100.0 fake=100.0\n",
      "Iteration 19: real=100.0 fake=100.0\n",
      "Iteration 20: real=100.0 fake=100.0\n",
      "Iteration 21: real=100.0 fake=100.0\n",
      "Iteration 22: real=100.0 fake=100.0\n",
      "Iteration 23: real=100.0 fake=100.0\n",
      "Iteration 24: real=100.0 fake=100.0\n",
      "Iteration 25: real=100.0 fake=100.0\n",
      "Iteration 26: real=100.0 fake=100.0\n",
      "Iteration 27: real=100.0 fake=100.0\n",
      "Iteration 28: real=100.0 fake=100.0\n",
      "Iteration 29: real=100.0 fake=100.0\n",
      "Iteration 30: real=100.0 fake=100.0\n",
      "Iteration 31: real=100.0 fake=100.0\n",
      "Iteration 32: real=100.0 fake=100.0\n",
      "Iteration 33: real=100.0 fake=100.0\n",
      "Iteration 34: real=100.0 fake=100.0\n",
      "Iteration 35: real=100.0 fake=100.0\n",
      "Iteration 36: real=100.0 fake=100.0\n",
      "Iteration 37: real=100.0 fake=100.0\n",
      "Iteration 38: real=100.0 fake=100.0\n",
      "Iteration 39: real=100.0 fake=100.0\n",
      "Iteration 40: real=100.0 fake=100.0\n",
      "Iteration 41: real=100.0 fake=100.0\n",
      "Iteration 42: real=100.0 fake=100.0\n",
      "Iteration 43: real=100.0 fake=100.0\n",
      "Iteration 44: real=100.0 fake=100.0\n",
      "Iteration 45: real=100.0 fake=100.0\n",
      "Iteration 46: real=100.0 fake=100.0\n",
      "Iteration 47: real=100.0 fake=100.0\n",
      "Iteration 48: real=100.0 fake=100.0\n",
      "Iteration 49: real=100.0 fake=100.0\n",
      "Iteration 50: real=100.0 fake=100.0\n",
      "Iteration 51: real=100.0 fake=100.0\n",
      "Iteration 52: real=100.0 fake=100.0\n",
      "Iteration 53: real=100.0 fake=100.0\n",
      "Iteration 54: real=100.0 fake=100.0\n",
      "Iteration 55: real=100.0 fake=100.0\n",
      "Iteration 56: real=100.0 fake=100.0\n",
      "Iteration 57: real=100.0 fake=100.0\n",
      "Iteration 58: real=100.0 fake=100.0\n",
      "Iteration 59: real=100.0 fake=100.0\n",
      "Iteration 60: real=100.0 fake=100.0\n",
      "Iteration 61: real=100.0 fake=100.0\n",
      "Iteration 62: real=100.0 fake=100.0\n",
      "Iteration 63: real=100.0 fake=100.0\n",
      "Iteration 64: real=100.0 fake=100.0\n",
      "Iteration 65: real=100.0 fake=100.0\n",
      "Iteration 66: real=100.0 fake=100.0\n",
      "Iteration 67: real=100.0 fake=100.0\n",
      "Iteration 68: real=100.0 fake=100.0\n",
      "Iteration 69: real=100.0 fake=100.0\n",
      "Iteration 70: real=100.0 fake=100.0\n",
      "Iteration 71: real=100.0 fake=100.0\n",
      "Iteration 72: real=100.0 fake=100.0\n",
      "Iteration 73: real=100.0 fake=100.0\n",
      "Iteration 74: real=100.0 fake=100.0\n",
      "Iteration 75: real=100.0 fake=100.0\n",
      "Iteration 76: real=100.0 fake=100.0\n",
      "Iteration 77: real=100.0 fake=100.0\n",
      "Iteration 78: real=100.0 fake=100.0\n",
      "Iteration 79: real=100.0 fake=100.0\n",
      "Iteration 80: real=100.0 fake=100.0\n",
      "Iteration 81: real=100.0 fake=100.0\n",
      "Iteration 82: real=100.0 fake=100.0\n",
      "Iteration 83: real=100.0 fake=100.0\n",
      "Iteration 84: real=100.0 fake=100.0\n",
      "Iteration 85: real=100.0 fake=100.0\n",
      "Iteration 86: real=100.0 fake=100.0\n",
      "Iteration 87: real=100.0 fake=100.0\n",
      "Iteration 88: real=100.0 fake=100.0\n",
      "Iteration 89: real=100.0 fake=100.0\n",
      "Iteration 90: real=100.0 fake=100.0\n",
      "Iteration 91: real=100.0 fake=100.0\n",
      "Iteration 92: real=100.0 fake=100.0\n",
      "Iteration 93: real=100.0 fake=100.0\n",
      "Iteration 94: real=100.0 fake=100.0\n",
      "Iteration 95: real=100.0 fake=100.0\n",
      "Iteration 96: real=100.0 fake=100.0\n",
      "Iteration 97: real=100.0 fake=100.0\n",
      "Iteration 98: real=100.0 fake=100.0\n",
      "Iteration 99: real=100.0 fake=100.0\n",
      "Iteration 100: real=100.0 fake=100.0\n"
     ]
    }
   ],
   "source": [
    "discriminator.train(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generator\n",
    "\n",
    "Next we will create a generator, which will learn how to create new \"handwritten\" digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    \"\"\"\n",
    "    The GAN's Generator\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        kernel=(4, 4),\n",
    "        strides=(3, 3),\n",
    "        padding=\"same\", \n",
    "        activation=\"sigmoid\", \n",
    "        latent_dimensions=100\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        kernel : tuple (default: (4,4))\n",
    "            Specifies the height & width of the 2D convolutional window.\n",
    "\n",
    "        strides : tuple (default: (2, 2))\n",
    "            The strides of the convolution along the height & width.\n",
    "            \n",
    "        padding : string, one of \"valid\" or \"same\" (default: \"same\")\n",
    "            One of \"valid\" or \"same\" (case-insensitive). \n",
    "            \"valid\" means no padding. \"same\" results in padding evenly\n",
    "            to the left/right or up/down of the input such that output\n",
    "            has the same height/width dimension as the input.\n",
    "            \n",
    "        activation : string (default: \"sigmoid\")\n",
    "            Activation function to use. See `keras.activations`\n",
    "            \n",
    "        latent_dimensions : int (default: 100)\n",
    "            Number of latent dimensions in the deep learning model\n",
    "        \"\"\"\n",
    "        self.kernel = kernel\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.latent = latent_dimensions\n",
    "    \n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Construct a Sequential model with a Dense layer capable\n",
    "        of producing 7x7 images. \n",
    "        Upsample the dimensions first to 14x14, and then to 28x28\n",
    "        \"\"\"\n",
    "        self.model = Sequential()\n",
    "        n_nodes = 128 * 7 * 7\n",
    "        self.model.add(Dense(n_nodes, input_dim=self.latent))\n",
    "        self.model.add(ReLU())\n",
    "        self.model.add(Reshape((7, 7, 128)))\n",
    "        self.model.add(Conv2DTranspose(\n",
    "            128, \n",
    "            self.kernel, \n",
    "            strides=self.strides, \n",
    "            padding=self.padding\n",
    "        ))\n",
    "        self.model.add(ReLU())\n",
    "        self.model.add(Conv2DTranspose(\n",
    "            128, \n",
    "            self.kernel, \n",
    "            strides=self.strides, \n",
    "            padding=self.padding\n",
    "        ))\n",
    "        self.model.add(ReLU())\n",
    "        self.model.add(Conv2D(\n",
    "            1, \n",
    "            (7, 7), \n",
    "            activation=self.activation, \n",
    "            padding=self.padding\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 21, 21, 128)       262272    \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 63, 63, 128)       262272    \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 63, 63, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 63, 63, 1)         6273      \n",
      "=================================================================\n",
      "Total params: 1,164,289\n",
      "Trainable params: 1,164,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = Generator()\n",
    "generator.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
